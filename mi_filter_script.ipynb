{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) filter mono- and intralinks on particle level / particle specific before merger script\n",
    "\n",
    "\n",
    "- Read the .csv files and delete 3 columns which were added by merger script\n",
    "\n",
    "Python 3.7.3\n",
    "pandas 0.25.1\n",
    "numpy 1.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to pop out one column and position it somewhere else in the dataframe (pops out like popcorn,\n",
    "#is thereby also deleted at the old position and inserted at the new one)\n",
    "def move_column_inplace(df, col, pos):\n",
    "    col = df.pop(col)\n",
    "    df.insert(pos, col.name, col)\n",
    "    return df\n",
    "\n",
    "#function used to make sure that the A allele of paralog (homologous) r-proteins is the first entry in order \n",
    "#to map the r-protein timing of the Cruz/ Woolford 2015 paper to the r-protein clustering in this study\n",
    "def myfunc(x,y,boolean):\n",
    "    if boolean:\n",
    "        return y\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def stringreplace(df):\n",
    "    df['XLType']=df['XLType'].str.replace ('decoy ', '')\n",
    "    df['XLType']=df['XLType'].str.replace ('intralink', 'intra-protein xl')\n",
    "    df['XLType']=df['XLType'].str.replace ('intra/inter xl', 'intra-protein xl')\n",
    "    return df\n",
    "    \n",
    "def homology_check(df):\n",
    "#important to correct for homologous proteins (e.g. ribosomal proteins in yeast) during def monolink_filter().\n",
    "#If no homologous protein sequences are contained in the search databases used for xQuest, (hit_database AND(!) decoy_database) this function is not necessary.\n",
    "#Works only properly after def stringreplace().\n",
    "#If a peptide sequence fits to multiple proteins in the search database, xQuest writes all of these proteins into\n",
    "#the columns 'Protein1' and/or 'Protein2'. The proteins are separated by a comma in the column.\n",
    "#xQuest defines a link which involves homologous proteins as 'intra/inter- xl'. Usually these links should count as\n",
    "#'intra-protein xl'. However, some links (e.g. links which involve a protein and the decoy_reverse_protein sequence) \n",
    "#are also marked as 'intra/inter xl'. The proteins involved in these links do not have the same sequence, they only \n",
    "#have part of their named in common. This is why they should actually be defined as 'inter-protein xl'.\n",
    "#This function checks, if an 'intra-protein xl' is actually an 'intra-protein xl' \n",
    "#(between homologous proteins like  [sp|P36105|RL14A_YEAST, sp|P38754|RL14B_YEAST] and [sp|P36105|RL14A_YEAST, sp|P38754|RL14B_YEAST]) \n",
    "#or if it is an 'inter-protein xl' \n",
    "#(between non-homologous proteins like [sp|P36105|RL14A_YEAST, sp|P38754|RL14B_YEAST] and decoy_reverse_sp|P36105|RL14A_YEAST)\n",
    "\n",
    "    #check how many intra-protein xl were changed to inter-protein xl\n",
    "    test_xltype = df.groupby('XLType').apply(lambda x: len(x))\n",
    "    print(\"\\nThese are the XLTypes in your dataframe before correction for non-homologous proteins in intra-protein xls. \\n\" + str(test_xltype))    \n",
    "    \n",
    "    #create a temporary dataframe df_check_homol which contains only the problematic links\n",
    "    #(links with Type == 'intralink' are links on 1 peptide and have a '-' in column 'Protein2', these may not be checked for homology\n",
    "    #because def homology_check() would identify them as 'inter-protein xl' which would be wrong)\n",
    "    bool_mask1 = (df.XLType == 'intra-protein xl')\n",
    "    df_intra_temp1 = df[bool_mask1]\n",
    "    \n",
    "    bool_mask2 = (df_intra_temp1.Type != 'intralink')\n",
    "    df_check_homol = df_intra_temp1[bool_mask2]\n",
    "\n",
    "    #make lists out of all entries in one row of the columns 'Protein1' and 'Protein2'\n",
    "    df_check_homol = df_check_homol.assign(Protein1=df_check_homol['Protein1'].str.split(','))\n",
    "    df_check_homol = df_check_homol.assign(Protein2=df_check_homol['Protein2'].str.split(','))\n",
    "    \n",
    "    #check if a protein contained in the row-list of 'Protein1' column (e.g. [sp|P36105|RL14A_YEAST, sp|P38754|RL14B_YEAST])\n",
    "    #is also contained in the row-list of 'Protein2' column (e.g. [sp|P36105|RL14A_YEAST, sp|P38754|RL14B_YEAST])\n",
    "    #and save it as a boolean mask\n",
    "    \n",
    "    boo = df_check_homol.apply(lambda row: not set(row.Protein1).isdisjoint(set(row.Protein2)), axis=1)\n",
    "    \n",
    "    #add the boolean mask as an additional column termed 'Homology' to the temporary dataframe df_check_homol\n",
    "    df_check_homol.loc[:,'Homology'] = boo\n",
    "    \n",
    "    #see how many times 'Homology' == False (these links should actually be 'inter-protein xl')\n",
    "    print(\"\\nThe intralinks in your dataframe were tested for homologous proteins.\")\n",
    "    test_homology = df_check_homol.groupby('Homology').apply(lambda x: len(x))\n",
    "    print(\"\\nLinks with 'Homology' = False are actually 'inter-protein xl'.\\n\" + str(test_homology))\n",
    "    \n",
    "    #the temporary dataframe df_check_homol is merged with the original df which gets the new column 'Homology'\n",
    "    #therefore the lists in df_check_homol 'Protein1' and 'Protein2' are turned back into strings (to match the columns in df)\n",
    "    mask_string1 = df_check_homol['Protein1'].apply(lambda x: ','.join(map(str, x)))\n",
    "    mask_string2 = df_check_homol['Protein2'].apply(lambda x: ','.join(map(str, x)))\n",
    "    df_check_homol.loc[:,'Protein1'] = mask_string1\n",
    "    df_check_homol.loc[:,'Protein2'] = mask_string2\n",
    "\n",
    "    df = df.merge(df_check_homol, how='outer') \n",
    "    \n",
    "    #the 'XLType' in df is corrected to the term 'inter-protein xl' for all links with Homology == False\n",
    "    mask_homology_false = (df['Homology'] == False)\n",
    "    df['XLType'] = df['XLType'].mask(mask_homology_false, 'inter-protein xl')\n",
    "    \n",
    "    #check how many intra-protein xl were changed to inter-protein xl\n",
    "    test_xltype_corr = df.groupby('XLType').apply(lambda x: len(x))\n",
    "    print(\"\\nThese are the XLTypes in your dataframe after correction for 'intra'-protein links between non-homologous proteins.\\n\" + str(test_xltype_corr))\n",
    "    \n",
    "    return df\n",
    "  \n",
    "def monolink_filter(df):\n",
    "    #first get a list of all proteins for which a monolink or a intralink was found\n",
    "    #then filter the original table with this list (or actually with this set)\n",
    "    monolink_df = df[df.XLType == 'monolink']\n",
    "    protein_list_monolinks1 = monolink_df['Protein1'].tolist()\n",
    "    protein_list_monolinks2 = monolink_df['Protein2'].tolist()\n",
    "\n",
    "    intralink_df = df[df.XLType == 'intra-protein xl']\n",
    "    protein_list_intralinks1 = intralink_df['Protein1'].tolist()\n",
    "    protein_list_intralinks2 = intralink_df['Protein2'].tolist()\n",
    "\n",
    "    #concatenate lists (containing comma separated entries)\n",
    "    filter_list = protein_list_intralinks1 + protein_list_monolinks1 + protein_list_monolinks2 + protein_list_intralinks2\n",
    "\n",
    "    #make a set out of the list: a set can contain every entry only once (that's what we want)\n",
    "    #this set contains the entries as they come from xquest: if a peptide can belong to multiple proteins out of homology reasons,\n",
    "    #all of these proteins will be contained in the column 'Protein1' as a connected string separated by a comma \n",
    "    unique_filter_list = set(filter_list)\n",
    "\n",
    "    #in order to not miss a protein, for which a monolink was found we make a second set which contains only single proteins\n",
    "    #(not multiple ones as one entry in a connected string separated by commas)\n",
    "    #therefore we have to explode the table on Protein1 and Protein2 column\n",
    "    #don't continue to work with the exploded table after the list with the single proteins\n",
    "    df_ex1 = df.assign(Protein1=df['Protein1'].str.split(',')).explode('Protein1')\n",
    "    df_ex2 = df_ex1.assign(Protein2=df_ex1['Protein2'].str.split(',')).explode('Protein2')\n",
    "\n",
    "    monolink_df_ex = df_ex2[df_ex2.XLType == 'monolink']\n",
    "    protein_list_monolinks_ex1 = monolink_df_ex['Protein1'].tolist()\n",
    "    protein_list_monolinks_ex2 = monolink_df_ex['Protein2'].tolist()\n",
    "\n",
    "    intralink_df_ex = df_ex2[df_ex2.XLType == 'intra-protein xl']\n",
    "    protein_list_intralinks_ex1 = intralink_df_ex['Protein1'].tolist()\n",
    "    protein_list_intralinks_ex2 = intralink_df_ex['Protein2'].tolist()\n",
    "\n",
    "    #concatenate exploded lists (containing single proteins)\n",
    "    filter_list_ex = protein_list_intralinks_ex1 + protein_list_intralinks_ex2 + protein_list_monolinks_ex1 + protein_list_monolinks_ex2\n",
    "\n",
    "    unique_filter_list_ex = set(filter_list_ex)\n",
    "\n",
    "    #make a set which contains the comma separated entries and also the single proteins\n",
    "    #this set contains all proteins for which a mono- or intralink was identified\n",
    "    #it also contains a '-' which is important for the next step, when we filter for proteins with mono- or intralinks\n",
    "    new_set = unique_filter_list | unique_filter_list_ex\n",
    "\n",
    "    #filter for proteins with mono- or intralinks in both Protein1 and Protein2\n",
    "    isin_df = df[(df['Protein1'].isin(new_set))&(df['Protein2'].isin(new_set))]\n",
    "    return isin_df\n",
    "\n",
    "#function to return the name of a dataframe\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "\n",
    "#function reads in 3 dataframes and generates a small helper dataframe containing the names \n",
    "#of the input dataframes\n",
    "#each dataframe gets a new column 'origin_df' containing the name of the input dataframe\n",
    "#the 3 input dataframes with the new column are concatenated\n",
    "#stringreplace and homology_check have to be used in order to correct for homologous proteins \n",
    "#(e.g. ribosomal proteins in yeast) during def monolink_filter()\n",
    "#only links >= ld-Score 25 are considered for the mono-/ intralink filter: only proteins which \n",
    "#have a mono or intralink >= 25 are considered for further analysis; links to all other proteins\n",
    "#are filtered out by the function monolink_filter ()\n",
    "#the filtered dataframe is splitted to 3 output dataframes of the biological repliactes \n",
    "#containing only links >= 25 to proteins which have a mono- or intralink >=25\n",
    "#the 3 output dataframes are saved as .csv files and the concatenated dataframe is returned\n",
    "def mi_filter_particle(df_1, df_2, df_3):\n",
    "    df_hlp = pd.DataFrame([get_df_name(df_1),get_df_name(df_2),get_df_name(df_3)])\n",
    "    df_1['origin_df'] = df_hlp.iloc[0,0]\n",
    "    df_2['origin_df'] = df_hlp.iloc[1,0]\n",
    "    df_3['origin_df'] = df_hlp.iloc[2,0]\n",
    "    df = pd.concat([df_1, df_2, df_3])\n",
    "    df = stringreplace(df)\n",
    "    df = homology_check(df)\n",
    "    df = df[df['ld-Score']>=20]\n",
    "    df = monolink_filter(df)\n",
    "    df_1_f = df[df['origin_df']==df_hlp.iloc[0,0]]\n",
    "    filename_1 = os.path.join(root, (df_hlp.iloc[0,0]+'_mifp.csv'))\n",
    "    df_1_f.to_csv(filename_1)\n",
    "    df_2_f = df[df['origin_df']==df_hlp.iloc[1,0]]\n",
    "    filename_2 = os.path.join(root, (df_hlp.iloc[1,0]+'_mifp.csv'))\n",
    "    df_2_f.to_csv(filename_2)\n",
    "    df_3_f = df[df['origin_df']==df_hlp.iloc[2,0]]\n",
    "    filename_3 = os.path.join(root, (df_hlp.iloc[2,0]+'_mifp.csv'))\n",
    "    df_3_f.to_csv(filename_3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'mi-filter' \n",
    "if not os.path.exists(root):\n",
    "    os.makedirs(root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control pulldown (wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the XLTypes in your dataframe before correction for non-homologous proteins in intra-protein xls. \n",
      "XLType\n",
      "inter-protein xl    1256\n",
      "intra-protein xl     418\n",
      "monolink             560\n",
      "dtype: int64\n",
      "\n",
      "The intralinks in your dataframe were tested for homologous proteins.\n",
      "\n",
      "Links with 'Homology' = False are actually 'inter-protein xl'.\n",
      "Homology\n",
      "False     51\n",
      "True     317\n",
      "dtype: int64\n",
      "\n",
      "These are the XLTypes in your dataframe after correction for 'intra'-protein links between non-homologous proteins.\n",
      "XLType\n",
      "inter-protein xl    1307\n",
      "intra-protein xl     367\n",
      "monolink             560\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_I = pd.read_csv('wt_1_small.csv', sep=None, engine='python')\n",
    "df_II = pd.read_csv('wt_2_small.csv', sep=None, engine='python')\n",
    "df_III = pd.read_csv('wt_3_small.csv', sep=None, engine='python')\n",
    "\n",
    "df_concat_WT = mi_filter_particle(df_I, df_II, df_III)\n",
    "df_concat_WT.to_csv('mi-filter_sum.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
